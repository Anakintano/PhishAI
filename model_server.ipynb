{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":8502378,"datasetId":5074342,"databundleVersionId":8643771,"isSourceIdPinned":false},{"sourceType":"datasetVersion","sourceId":2374680,"datasetId":1434901,"databundleVersionId":2416540,"isSourceIdPinned":false}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nMulti-Agent Phishing Detection System with Kaggle Datasets\nUses DistilBERT models with comprehensive evaluation metrics from research papers\n\"\"\"\n\n# Install required packages\n!pip install transformers datasets torch scikit-learn pandas accelerate kagglehub matplotlib seaborn tabulate -q\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport os\nimport glob\nfrom transformers import (\n    DistilBertTokenizer, \n    DistilBertForSequenceClassification,\n    Trainer, \n    TrainingArguments,\n    EarlyStoppingCallback\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    accuracy_score, \n    precision_recall_fscore_support, \n    classification_report,\n    confusion_matrix,\n    roc_curve,\n    auc,\n    roc_auc_score\n)\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport kagglehub\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# ============================================================================\n# STEP 1: Download and Load Datasets from Kaggle\n# ============================================================================\n\nprint(\"=\" * 70)\nprint(\"STEP 1: DOWNLOADING DATASETS FROM KAGGLE\")\nprint(\"=\" * 70)\n\n# Download Email Phishing Dataset\nprint(\"\\nüì• Downloading Email Phishing Dataset...\")\nemail_path = kagglehub.dataset_download(\"naserabdullahalam/phishing-email-dataset\")\nprint(f\"Email dataset path: {email_path}\")\n\n# Download URL Phishing Dataset\nprint(\"\\nüì• Downloading URL Phishing Dataset...\")\nurl_path = kagglehub.dataset_download(\"shashwatwork/web-page-phishing-detection-dataset\")\nprint(f\"URL dataset path: {url_path}\")\n\n# ============================================================================\n# STEP 2: Load and Process Email Dataset\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"STEP 2: LOADING AND PROCESSING EMAIL DATASET\")\nprint(\"=\" * 70)\n\n# Find CSV files in email dataset directory\nemail_files = glob.glob(os.path.join(email_path, \"**/*.csv\"), recursive=True)\nprint(f\"\\nFound {len(email_files)} email files\")\n\n# Try to load the main phishing_email.csv first\nemail_df = None\npreferred_files = ['phishing_email.csv', 'CEAS_08.csv']\n\nfor preferred in preferred_files:\n    for file in email_files:\n        if preferred in file:\n            try:\n                temp_df = pd.read_csv(file)\n                print(f\"\\n‚úì Loading {os.path.basename(file)}\")\n                print(f\"  Columns: {temp_df.columns.tolist()}\")\n                print(f\"  Shape: {temp_df.shape}\")\n                \n                # Try to identify text and label columns\n                text_col = None\n                label_col = None\n                \n                for col in temp_df.columns:\n                    col_lower = col.lower()\n                    if 'body' in col_lower or 'email' in col_lower or 'text' in col_lower:\n                        text_col = col\n                    if 'label' in col_lower or 'class' in col_lower:\n                        label_col = col\n                \n                if text_col and label_col:\n                    email_df = temp_df[[text_col, label_col]].copy()\n                    email_df.columns = ['text', 'label']\n                    print(f\"  Using: text='{text_col}', label='{label_col}'\")\n                    break\n            except Exception as e:\n                print(f\"  Error: {e}\")\n                continue\n    \n    if email_df is not None:\n        break\n\nif email_df is None:\n    raise ValueError(\"Could not load email dataset. Please check the file structure.\")\n\n# Clean email dataset\nemail_df = email_df.dropna()\nemail_df['text'] = email_df['text'].astype(str)\nemail_df['text'] = email_df['text'].str[:1000]  # Limit text length\n\n# Normalize labels to 0 (legitimate) and 1 (phishing)\nunique_labels = email_df['label'].unique()\nprint(f\"\\n  Unique labels: {unique_labels}\")\n\nif email_df['label'].dtype == 'object':\n    phishing_keywords = ['phish', 'spam', '1', 'true']\n    email_df['label'] = email_df['label'].apply(\n        lambda x: 1 if any(key in str(x).lower() for key in phishing_keywords) else 0\n    )\nelse:\n    email_df['label'] = email_df['label'].apply(lambda x: 1 if x != 0 else 0)\n\nprint(f\"\\n‚úì Email dataset processed:\")\nprint(f\"  Total: {len(email_df)} samples\")\nprint(f\"  Legitimate: {sum(email_df['label'] == 0)}\")\nprint(f\"  Phishing: {sum(email_df['label'] == 1)}\")\n\n# ============================================================================\n# STEP 3: Load and Process URL Dataset\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"STEP 3: LOADING AND PROCESSING URL DATASET\")\nprint(\"=\" * 70)\n\n# Find CSV files in URL dataset directory\nurl_files = glob.glob(os.path.join(url_path, \"**/*.csv\"), recursive=True)\nprint(f\"\\nFound {len(url_files)} URL files\")\n\n# Load URL dataset\nurl_df = None\nfor file in url_files:\n    try:\n        temp_df = pd.read_csv(file)\n        print(f\"\\n‚úì Loading {os.path.basename(file)}\")\n        print(f\"  Columns: {temp_df.columns.tolist()[:10]}...\")  # Show first 10\n        print(f\"  Shape: {temp_df.shape}\")\n        \n        # Look specifically for 'url' and 'status' columns\n        if 'url' in temp_df.columns and 'status' in temp_df.columns:\n            url_df = temp_df[['url', 'status']].copy()\n            url_df.columns = ['text', 'label']\n            print(f\"  Using: text='url', label='status'\")\n            break\n        elif 'url' in temp_df.columns:\n            # Find any potential label column\n            for col in temp_df.columns:\n                if col.lower() in ['label', 'class', 'status', 'target']:\n                    url_df = temp_df[['url', col]].copy()\n                    url_df.columns = ['text', 'label']\n                    print(f\"  Using: text='url', label='{col}'\")\n                    break\n            if url_df is not None:\n                break\n                \n    except Exception as e:\n        print(f\"  Error: {e}\")\n        continue\n\nif url_df is None:\n    raise ValueError(\"Could not load URL dataset. Please check the file structure.\")\n\n# Clean URL dataset\nurl_df = url_df.dropna()\nurl_df['text'] = url_df['text'].astype(str)\nurl_df['text'] = url_df['text'].str[:500]  # Limit URL length\n\n# Normalize labels to 0 (legitimate) and 1 (phishing)\nunique_labels = url_df['label'].unique()\nprint(f\"\\n  Unique labels: {unique_labels}\")\n\nif url_df['label'].dtype == 'object':\n    phishing_keywords = ['phish', 'bad', 'malicious', '1']\n    url_df['label'] = url_df['label'].apply(\n        lambda x: 1 if any(key in str(x).lower() for key in phishing_keywords) else 0\n    )\nelse:\n    url_df['label'] = url_df['label'].apply(lambda x: 1 if x != 0 else 0)\n\nprint(f\"\\n‚úì URL dataset processed:\")\nprint(f\"  Total: {len(url_df)} samples\")\nprint(f\"  Legitimate: {sum(url_df['label'] == 0)}\")\nprint(f\"  Phishing: {sum(url_df['label'] == 1)}\")\nprint(f\"\\n  Sample URLs:\")\nfor i in range(min(3, len(url_df))):\n    print(f\"    {url_df.iloc[i]['text'][:60]}... (label: {url_df.iloc[i]['label']})\")\n\n# ============================================================================\n# STEP 4: Balance Datasets if Needed\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"STEP 4: BALANCING DATASETS\")\nprint(\"=\" * 70)\n\ndef balance_dataset(df, max_samples=5000):\n    \"\"\"Balance dataset by undersampling majority class\"\"\"\n    legitimate = df[df['label'] == 0]\n    phishing = df[df['label'] == 1]\n    \n    # Determine the minimum count\n    min_count = min(len(legitimate), len(phishing), max_samples)\n    \n    # Sample equally from both classes\n    legitimate_balanced = legitimate.sample(n=min_count, random_state=42)\n    phishing_balanced = phishing.sample(n=min_count, random_state=42)\n    \n    # Combine and shuffle\n    balanced_df = pd.concat([legitimate_balanced, phishing_balanced])\n    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    return balanced_df\n\n# Balance email dataset\nemail_df_balanced = balance_dataset(email_df, max_samples=5000)\nprint(f\"\\n‚úì Email dataset balanced:\")\nprint(f\"  Total: {len(email_df_balanced)} samples\")\nprint(f\"  Legitimate: {sum(email_df_balanced['label'] == 0)}\")\nprint(f\"  Phishing: {sum(email_df_balanced['label'] == 1)}\")\n\n# Balance URL dataset\nurl_df_balanced = balance_dataset(url_df, max_samples=5000)\nprint(f\"\\n‚úì URL dataset balanced:\")\nprint(f\"  Total: {len(url_df_balanced)} samples\")\nprint(f\"  Legitimate: {sum(url_df_balanced['label'] == 0)}\")\nprint(f\"  Phishing: {sum(url_df_balanced['label'] == 1)}\")\n\n# ============================================================================\n# STEP 5: Create Umpire Dataset\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"STEP 5: CREATING UMPIRE DATASET\")\nprint(\"=\" * 70)\n\n# Create umpire dataset (0=email, 1=url)\nemail_umpire = email_df_balanced[['text']].copy()\nemail_umpire['label'] = 0  # Email category\n\nurl_umpire = url_df_balanced[['text']].copy()\nurl_umpire['label'] = 1  # URL category\n\numpire_df = pd.concat([email_umpire, url_umpire], ignore_index=True)\numpire_df = umpire_df.sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(f\"‚úì Umpire dataset created: {len(umpire_df)} samples\")\nprint(f\"  Email samples: {sum(umpire_df['label'] == 0)}\")\nprint(f\"  URL samples: {sum(umpire_df['label'] == 1)}\")\n\n# ============================================================================\n# STEP 6: Custom Dataset Class\n# ============================================================================\n\nclass PhishingDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# ============================================================================\n# STEP 7: Enhanced Training Function with Comprehensive Metrics\n# ============================================================================\n\ndef calculate_tpr_at_fpr(y_true, y_scores, fpr_threshold=0.01):\n    \"\"\"Calculate TPR at specific FPR threshold (from URLTran paper)\"\"\"\n    try:\n        fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n        idx = np.where(fpr <= fpr_threshold)[0]\n        if len(idx) > 0:\n            return tpr[idx[-1]]\n    except:\n        pass\n    return 0.0\n\ndef plot_roc_curve(y_true, y_scores, model_name, save_path):\n    \"\"\"Plot ROC curve\"\"\"\n    try:\n        fpr, tpr, _ = roc_curve(y_true, y_scores)\n        roc_auc = auc(fpr, tpr)\n        \n        plt.figure(figsize=(10, 8))\n        plt.plot(fpr, tpr, color='darkorange', lw=2, \n                 label=f'ROC curve (AUC = {roc_auc:.4f})')\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve - {model_name}')\n        plt.legend(loc=\"lower right\")\n        plt.grid(True, alpha=0.3)\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.close()\n        print(f\"  ‚úì ROC curve saved to {save_path}\")\n    except Exception as e:\n        print(f\"  ‚ö† Could not plot ROC curve: {e}\")\n\ndef plot_confusion_matrix(y_true, y_pred, model_name, save_path):\n    \"\"\"Plot confusion matrix\"\"\"\n    try:\n        cm = confusion_matrix(y_true, y_pred)\n        \n        plt.figure(figsize=(8, 6))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                    xticklabels=['Legitimate', 'Phishing'],\n                    yticklabels=['Legitimate', 'Phishing'])\n        plt.title(f'Confusion Matrix - {model_name}')\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.close()\n        print(f\"  ‚úì Confusion matrix saved to {save_path}\")\n    except Exception as e:\n        print(f\"  ‚ö† Could not plot confusion matrix: {e}\")\n\ndef train_model(train_texts, train_labels, val_texts, val_labels, \n                model_name, num_epochs=3, batch_size=16):\n    \"\"\"\n    Train DistilBERT model with comprehensive evaluation metrics\n    \"\"\"\n    \n    print(f\"\\n{'=' * 70}\")\n    print(f\"Training {model_name}\")\n    print(f\"{'=' * 70}\")\n    \n    # Initialize tokenizer and model\n    print(f\"\\nüì• Loading DistilBERT tokenizer and model...\")\n    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n    model = DistilBertForSequenceClassification.from_pretrained(\n        'distilbert-base-uncased',\n        num_labels=2,\n        dropout=0.3,\n        attention_dropout=0.3\n    )\n    \n    # Tokenize datasets\n    print(f\"üìù Tokenizing {len(train_texts)} training samples...\")\n    train_encodings = tokenizer(\n        train_texts,\n        truncation=True,\n        padding=True,\n        max_length=128,\n        return_tensors='pt'\n    )\n    \n    print(f\"üìù Tokenizing {len(val_texts)} validation samples...\")\n    val_encodings = tokenizer(\n        val_texts,\n        truncation=True,\n        padding=True,\n        max_length=128,\n        return_tensors='pt'\n    )\n    \n    # Create datasets\n    train_dataset = PhishingDataset(train_encodings, train_labels)\n    val_dataset = PhishingDataset(val_encodings, val_labels)\n    \n    # Compute metrics\n    def compute_metrics(pred):\n        labels = pred.label_ids\n        preds = pred.predictions.argmax(-1)\n        precision, recall, f1, _ = precision_recall_fscore_support(\n            labels, preds, average='binary', zero_division=0\n        )\n        acc = accuracy_score(labels, preds)\n        return {\n            'accuracy': acc,\n            'f1': f1,\n            'precision': precision,\n            'recall': recall\n        }\n    \n    # Training arguments\n    training_args = TrainingArguments(\n        output_dir=f'./results_{model_name}',\n        num_train_epochs=num_epochs,\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size,\n        warmup_steps=50,\n        weight_decay=0.01,\n        logging_dir=f'./logs_{model_name}',\n        logging_steps=50,\n        eval_strategy=\"steps\",\n        eval_steps=100,\n        save_strategy=\"steps\",\n        save_steps=100,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1\",\n        greater_is_better=True,\n        save_total_limit=1,\n        learning_rate=2e-5,\n        max_grad_norm=1.0,\n        fp16=torch.cuda.is_available(),\n        report_to=\"none\",  # Disable wandb\n    )\n    \n    # Initialize trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics,\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n    )\n    \n    # Train\n    print(f\"\\nüöÄ Starting training for {num_epochs} epochs...\")\n    trainer.train()\n    \n    # Detailed evaluation on validation set\n    print(f\"\\nüìä Computing comprehensive metrics...\")\n    predictions = trainer.predict(val_dataset)\n    y_pred = predictions.predictions.argmax(-1)\n    y_scores = torch.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n    y_true = val_labels\n    \n    # Calculate all metrics\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        y_true, y_pred, average='binary', zero_division=0\n    )\n    accuracy = accuracy_score(y_true, y_pred)\n    \n    # ROC-AUC and TPR@FPR metrics (from URLTran paper)\n    try:\n        roc_auc = roc_auc_score(y_true, y_scores)\n    except:\n        roc_auc = 0.0\n    \n    tpr_001 = calculate_tpr_at_fpr(y_true, y_scores, 0.0001)  # 0.01% FPR\n    tpr_01 = calculate_tpr_at_fpr(y_true, y_scores, 0.001)    # 0.1% FPR\n    tpr_1 = calculate_tpr_at_fpr(y_true, y_scores, 0.01)      # 1% FPR\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    \n    # Calculate per-class metrics (from RoBERTa paper)\n    precision_per_class, recall_per_class, f1_per_class, support = \\\n        precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n    \n    results = {\n        'accuracy': float(accuracy),\n        'precision': float(precision),\n        'recall': float(recall),\n        'f1_score': float(f1),\n        'roc_auc': float(roc_auc),\n        'tpr@0.01%_fpr': float(tpr_001),\n        'tpr@0.1%_fpr': float(tpr_01),\n        'tpr@1%_fpr': float(tpr_1),\n        'confusion_matrix': {\n            'true_negative': int(tn),\n            'false_positive': int(fp),\n            'false_negative': int(fn),\n            'true_positive': int(tp)\n        },\n        'per_class_metrics': {\n            'legitimate': {\n                'precision': float(precision_per_class[0]),\n                'recall': float(recall_per_class[0]),\n                'f1_score': float(f1_per_class[0]),\n                'support': int(support[0])\n            },\n            'phishing': {\n                'precision': float(precision_per_class[1]),\n                'recall': float(recall_per_class[1]),\n                'f1_score': float(f1_per_class[1]),\n                'support': int(support[1])\n            }\n        }\n    }\n    \n    # Print results\n    print(f\"\\n{'=' * 70}\")\n    print(f\"VALIDATION RESULTS - {model_name}\")\n    print(f\"{'=' * 70}\")\n    print(f\"Accuracy:           {accuracy:.4f}\")\n    print(f\"Precision:          {precision:.4f}\")\n    print(f\"Recall:             {recall:.4f}\")\n    print(f\"F1-Score:           {f1:.4f}\")\n    print(f\"ROC-AUC:            {roc_auc:.4f}\")\n    print(f\"\\nTPR at Different FPR Thresholds:\")\n    print(f\"  TPR @ 0.01% FPR:  {tpr_001:.4f}\")\n    print(f\"  TPR @ 0.1% FPR:   {tpr_01:.4f}\")\n    print(f\"  TPR @ 1% FPR:     {tpr_1:.4f}\")\n    print(f\"\\nConfusion Matrix:\")\n    print(f\"  TN: {tn:6d}  |  FP: {fp:6d}\")\n    print(f\"  FN: {fn:6d}  |  TP: {tp:6d}\")\n    print(f\"\\nPer-Class Metrics:\")\n    print(f\"  Legitimate - P: {precision_per_class[0]:.4f}, R: {recall_per_class[0]:.4f}, F1: {f1_per_class[0]:.4f}\")\n    print(f\"  Phishing   - P: {precision_per_class[1]:.4f}, R: {recall_per_class[1]:.4f}, F1: {f1_per_class[1]:.4f}\")\n    \n    # Generate plots\n    model_clean_name = model_name.lower().replace(\" \", \"_\")\n    plot_roc_curve(y_true, y_scores, model_name, f'{model_clean_name}_roc_curve.png')\n    plot_confusion_matrix(y_true, y_pred, model_name, f'{model_clean_name}_confusion_matrix.png')\n    \n    # Save model\n    model_path = f'./{model_clean_name}'\n    trainer.save_model(model_path)\n    tokenizer.save_pretrained(model_path)\n    print(f\"\\n‚úì Model saved to {model_path}\")\n    \n    return model, tokenizer, results\n\n# ============================================================================\n# STEP 8: Train All Three Models\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"STEP 8: TRAINING ALL MODELS\")\nprint(\"=\" * 70)\n\n# Prepare splits for Email Phishing Model\nprint(\"\\nüìã Preparing Email Phishing Model data...\")\nemail_texts = email_df_balanced['text'].tolist()\nemail_labels = email_df_balanced['label'].tolist()\nemail_train_texts, email_val_texts, email_train_labels, email_val_labels = train_test_split(\n    email_texts, email_labels, test_size=0.2, random_state=42, stratify=email_labels\n)\nprint(f\"  Train: {len(email_train_texts)}, Val: {len(email_val_texts)}\")\n\n# Prepare splits for URL Phishing Model\nprint(\"\\nüìã Preparing URL Phishing Model data...\")\nurl_texts = url_df_balanced['text'].tolist()\nurl_labels = url_df_balanced['label'].tolist()\nurl_train_texts, url_val_texts, url_train_labels, url_val_labels = train_test_split(\n    url_texts, url_labels, test_size=0.2, random_state=42, stratify=url_labels\n)\nprint(f\"  Train: {len(url_train_texts)}, Val: {len(url_val_texts)}\")\n\n# Prepare splits for Umpire Model\nprint(\"\\nüìã Preparing Umpire Model data...\")\numpire_texts = umpire_df['text'].tolist()\numpire_labels = umpire_df['label'].tolist()\numpire_train_texts, umpire_val_texts, umpire_train_labels, umpire_val_labels = train_test_split(\n    umpire_texts, umpire_labels, test_size=0.2, random_state=42, stratify=umpire_labels\n)\nprint(f\"  Train: {len(umpire_train_texts)}, Val: {len(umpire_val_texts)}\")\n\n# Train Email Phishing Model\nemail_model, email_tokenizer, email_results = train_model(\n    email_train_texts, email_train_labels,\n    email_val_texts, email_val_labels,\n    \"Email_Phishing_Model\",\n    num_epochs=3,\n    batch_size=16\n)\n\n# Train URL Phishing Model\nurl_model, url_tokenizer, url_results = train_model(\n    url_train_texts, url_train_labels,\n    url_val_texts, url_val_labels,\n    \"URL_Phishing_Model\",\n    num_epochs=3,\n    batch_size=16\n)\n\n# Train Umpire Model\numpire_model, umpire_tokenizer, umpire_results = train_model(\n    umpire_train_texts, umpire_train_labels,\n    umpire_val_texts, umpire_val_labels,\n    \"Umpire_Model\",\n    num_epochs=3,\n    batch_size=16\n)\n\n# ============================================================================\n# STEP 9: Comparative Analysis and Summary\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"COMPREHENSIVE PERFORMANCE SUMMARY\")\nprint(\"=\" * 70)\n\nsummary = {\n    \"email_model\": {\n        \"dataset_size\": len(email_df_balanced),\n        \"train_samples\": len(email_train_texts),\n        \"val_samples\": len(email_val_texts),\n        \"metrics\": email_results\n    },\n    \"url_model\": {\n        \"dataset_size\": len(url_df_balanced),\n        \"train_samples\": len(url_train_texts),\n        \"val_samples\": len(url_val_texts),\n        \"metrics\": url_results\n    },\n    \"umpire_model\": {\n        \"dataset_size\": len(umpire_df),\n        \"train_samples\": len(umpire_train_texts),\n        \"val_samples\": len(umpire_val_texts),\n        \"metrics\": umpire_results\n    }\n}\n\n# Save comprehensive summary\nwith open('comprehensive_training_summary.json', 'w') as f:\n    json.dump(summary, f, indent=2)\n\n# Create comparison table\nprint(\"\\n\" + \"=\" * 70)\nprint(\"MODEL COMPARISON TABLE\")\nprint(\"=\" * 70)\nprint(f\"\\n{'Metric':<25} {'Email Model':<15} {'URL Model':<15} {'Umpire Model':<15}\")\nprint(\"-\" * 70)\n\nmetrics_to_compare = [\n    ('Accuracy', 'accuracy'),\n    ('Precision', 'precision'),\n    ('Recall', 'recall'),\n    ('F1-Score', 'f1_score'),\n    ('ROC-AUC', 'roc_auc'),\n    ('TPR @ 0.01% FPR', 'tpr@0.01%_fpr'),\n    ('TPR @ 0.1% FPR', 'tpr@0.1%_fpr'),\n    ('TPR @ 1% FPR', 'tpr@1%_fpr'),\n]\n\nfor metric_name, metric_key in metrics_to_compare:\n    email_val = email_results.get(metric_key, 0)\n    url_val = url_results.get(metric_key, 0)\n    umpire_val = umpire_results.get(metric_key, 0)\n    print(f\"{metric_name:<25} {email_val:<15.4f} {url_val:<15.4f} {umpire_val:<15.4f}\")\n\n# Baseline comparison (based on paper benchmarks)\nprint(\"\\n\" + \"=\" * 70)\nprint(\"BASELINE COMPARISON\")\nprint(\"=\" * 70)\nprint(\"\\nBased on research papers:\")\nprint(\"  RoBERTa (Email):     Accuracy: 98.45%, F1: 0.98\")\nprint(\"  URLTran (URL):       Accuracy: 99.67%, TPR@0.01%FPR: 86.80%\")\nprint(\"  URLNet (Baseline):   Accuracy: 99.45%, TPR@0.01%FPR: 71.20%\")\nprint(\"  Texception:          Accuracy: 99.66%, TPR@0.01%FPR: 52.15%\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"‚úÖ TRAINING COMPLETED SUCCESSFULLY!\")\nprint(\"=\" * 70)\nprint(\"\\nüì¶ Saved artifacts:\")\nprint(\"  1. ./email_phishing_model/\")\nprint(\"  2. ./url_phishing_model/\")\nprint(\"  3. ./umpire_model/\")\nprint(\"  4. comprehensive_training_summary.json\")\nprint(\"  5. ROC curves and confusion matrices (PNG files)\")\nprint(\"\\nüß™ Ready for testing! Use the testing code to evaluate.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T19:34:52.226427Z","iopub.execute_input":"2025-11-09T19:34:52.226736Z","iopub.status.idle":"2025-11-09T19:47:36.252602Z","shell.execute_reply.started":"2025-11-09T19:34:52.226713Z","shell.execute_reply":"2025-11-09T19:47:36.251711Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-11-09 19:36:24.585555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762716984.783492      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762716984.839148      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"======================================================================\nSTEP 1: DOWNLOADING DATASETS FROM KAGGLE\n======================================================================\n\nüì• Downloading Email Phishing Dataset...\nEmail dataset path: /kaggle/input/phishing-email-dataset\n\nüì• Downloading URL Phishing Dataset...\nURL dataset path: /kaggle/input/web-page-phishing-detection-dataset\n\n======================================================================\nSTEP 2: LOADING AND PROCESSING EMAIL DATASET\n======================================================================\n\nFound 7 email files\n\n‚úì Loading phishing_email.csv\n  Columns: ['text_combined', 'label']\n  Shape: (82486, 2)\n  Using: text='text_combined', label='label'\n\n  Unique labels: [0 1]\n\n‚úì Email dataset processed:\n  Total: 82486 samples\n  Legitimate: 39595\n  Phishing: 42891\n\n======================================================================\nSTEP 3: LOADING AND PROCESSING URL DATASET\n======================================================================\n\nFound 1 URL files\n\n‚úì Loading dataset_phishing.csv\n  Columns: ['url', 'length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', 'nb_and', 'nb_or']...\n  Shape: (11430, 89)\n  Using: text='url', label='status'\n\n  Unique labels: ['legitimate' 'phishing']\n\n‚úì URL dataset processed:\n  Total: 11430 samples\n  Legitimate: 5715\n  Phishing: 5715\n\n  Sample URLs:\n    http://www.crestonwood.com/router.php... (label: 0)\n    http://shadetreetechnology.com/V4/validation/a111aedc8ae390e... (label: 1)\n    https://support-appleld.com.secureupdate.duilawyeryork.com/a... (label: 1)\n\n======================================================================\nSTEP 4: BALANCING DATASETS\n======================================================================\n\n‚úì Email dataset balanced:\n  Total: 10000 samples\n  Legitimate: 5000\n  Phishing: 5000\n\n‚úì URL dataset balanced:\n  Total: 10000 samples\n  Legitimate: 5000\n  Phishing: 5000\n\n======================================================================\nSTEP 5: CREATING UMPIRE DATASET\n======================================================================\n‚úì Umpire dataset created: 20000 samples\n  Email samples: 10000\n  URL samples: 10000\n\n======================================================================\nSTEP 8: TRAINING ALL MODELS\n======================================================================\n\nüìã Preparing Email Phishing Model data...\n  Train: 8000, Val: 2000\n\nüìã Preparing URL Phishing Model data...\n  Train: 8000, Val: 2000\n\nüìã Preparing Umpire Model data...\n  Train: 16000, Val: 4000\n\n======================================================================\nTraining Email_Phishing_Model\n======================================================================\n\nüì• Loading DistilBERT tokenizer and model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf9ec0904c945ba84c081891fe3f92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5567e0fab3847f8b8879172ca0f0bae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af057f4305a54cb39a3a9fe56c399a21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c884490c793435eb4d040a92554a744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea5c8b7a65146a7bb9c4dc99e950334"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"üìù Tokenizing 8000 training samples...\nüìù Tokenizing 2000 validation samples...\n\nüöÄ Starting training for 3 epochs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='600' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [600/750 02:55 < 00:43, 3.41 it/s, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.278200</td>\n      <td>0.167722</td>\n      <td>0.940000</td>\n      <td>0.940179</td>\n      <td>0.937376</td>\n      <td>0.943000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.145200</td>\n      <td>0.111919</td>\n      <td>0.960500</td>\n      <td>0.960361</td>\n      <td>0.963746</td>\n      <td>0.957000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.101600</td>\n      <td>0.097456</td>\n      <td>0.970500</td>\n      <td>0.970661</td>\n      <td>0.965381</td>\n      <td>0.976000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.091000</td>\n      <td>0.109978</td>\n      <td>0.964000</td>\n      <td>0.963415</td>\n      <td>0.979339</td>\n      <td>0.948000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.113500</td>\n      <td>0.118339</td>\n      <td>0.963500</td>\n      <td>0.962812</td>\n      <td>0.981308</td>\n      <td>0.945000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.074200</td>\n      <td>0.129213</td>\n      <td>0.964000</td>\n      <td>0.963340</td>\n      <td>0.981328</td>\n      <td>0.946000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nüìä Computing comprehensive metrics...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nVALIDATION RESULTS - Email_Phishing_Model\n======================================================================\nAccuracy:           0.9705\nPrecision:          0.9654\nRecall:             0.9760\nF1-Score:           0.9707\nROC-AUC:            0.9941\n\nTPR at Different FPR Thresholds:\n  TPR @ 0.01% FPR:  0.2580\n  TPR @ 0.1% FPR:   0.5040\n  TPR @ 1% FPR:     0.8700\n\nConfusion Matrix:\n  TN:    965  |  FP:     35\n  FN:     24  |  TP:    976\n\nPer-Class Metrics:\n  Legitimate - P: 0.9757, R: 0.9650, F1: 0.9703\n  Phishing   - P: 0.9654, R: 0.9760, F1: 0.9707\n  ‚úì ROC curve saved to email_phishing_model_roc_curve.png\n  ‚úì Confusion matrix saved to email_phishing_model_confusion_matrix.png\n\n‚úì Model saved to ./email_phishing_model\n\n======================================================================\nTraining URL_Phishing_Model\n======================================================================\n\nüì• Loading DistilBERT tokenizer and model...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"üìù Tokenizing 8000 training samples...\nüìù Tokenizing 2000 validation samples...\n\nüöÄ Starting training for 3 epochs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [750/750 03:41, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.372400</td>\n      <td>0.399320</td>\n      <td>0.838500</td>\n      <td>0.817823</td>\n      <td>0.937904</td>\n      <td>0.725000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.260000</td>\n      <td>0.206217</td>\n      <td>0.919000</td>\n      <td>0.919162</td>\n      <td>0.917331</td>\n      <td>0.921000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.188100</td>\n      <td>0.241349</td>\n      <td>0.916000</td>\n      <td>0.912500</td>\n      <td>0.952174</td>\n      <td>0.876000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.192000</td>\n      <td>0.245665</td>\n      <td>0.913000</td>\n      <td>0.908228</td>\n      <td>0.960938</td>\n      <td>0.861000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.175600</td>\n      <td>0.210909</td>\n      <td>0.926500</td>\n      <td>0.924808</td>\n      <td>0.946597</td>\n      <td>0.904000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.166300</td>\n      <td>0.218029</td>\n      <td>0.924000</td>\n      <td>0.921649</td>\n      <td>0.951064</td>\n      <td>0.894000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.149800</td>\n      <td>0.228049</td>\n      <td>0.922000</td>\n      <td>0.918750</td>\n      <td>0.958696</td>\n      <td>0.882000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nüìä Computing comprehensive metrics...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nVALIDATION RESULTS - URL_Phishing_Model\n======================================================================\nAccuracy:           0.9265\nPrecision:          0.9466\nRecall:             0.9040\nF1-Score:           0.9248\nROC-AUC:            0.9798\n\nTPR at Different FPR Thresholds:\n  TPR @ 0.01% FPR:  0.3590\n  TPR @ 0.1% FPR:   0.5610\n  TPR @ 1% FPR:     0.7640\n\nConfusion Matrix:\n  TN:    949  |  FP:     51\n  FN:     96  |  TP:    904\n\nPer-Class Metrics:\n  Legitimate - P: 0.9081, R: 0.9490, F1: 0.9281\n  Phishing   - P: 0.9466, R: 0.9040, F1: 0.9248\n  ‚úì ROC curve saved to url_phishing_model_roc_curve.png\n  ‚úì Confusion matrix saved to url_phishing_model_confusion_matrix.png\n\n‚úì Model saved to ./url_phishing_model\n\n======================================================================\nTraining Umpire_Model\n======================================================================\n\nüì• Loading DistilBERT tokenizer and model...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"üìù Tokenizing 16000 training samples...\nüìù Tokenizing 4000 validation samples...\n\nüöÄ Starting training for 3 epochs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 500/1500 02:53 < 05:48, 2.87 it/s, Epoch 1/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.004800</td>\n      <td>0.000299</td>\n      <td>0.999750</td>\n      <td>0.999750</td>\n      <td>0.999500</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.000000</td>\n      <td>0.000132</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.000000</td>\n      <td>0.000126</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.000000</td>\n      <td>0.000114</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.000000</td>\n      <td>0.000104</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nüìä Computing comprehensive metrics...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nVALIDATION RESULTS - Umpire_Model\n======================================================================\nAccuracy:           1.0000\nPrecision:          1.0000\nRecall:             1.0000\nF1-Score:           1.0000\nROC-AUC:            1.0000\n\nTPR at Different FPR Thresholds:\n  TPR @ 0.01% FPR:  1.0000\n  TPR @ 0.1% FPR:   1.0000\n  TPR @ 1% FPR:     1.0000\n\nConfusion Matrix:\n  TN:   2000  |  FP:      0\n  FN:      0  |  TP:   2000\n\nPer-Class Metrics:\n  Legitimate - P: 1.0000, R: 1.0000, F1: 1.0000\n  Phishing   - P: 1.0000, R: 1.0000, F1: 1.0000\n  ‚úì ROC curve saved to umpire_model_roc_curve.png\n  ‚úì Confusion matrix saved to umpire_model_confusion_matrix.png\n\n‚úì Model saved to ./umpire_model\n\n======================================================================\nCOMPREHENSIVE PERFORMANCE SUMMARY\n======================================================================\n\n======================================================================\nMODEL COMPARISON TABLE\n======================================================================\n\nMetric                    Email Model     URL Model       Umpire Model   \n----------------------------------------------------------------------\nAccuracy                  0.9705          0.9265          1.0000         \nPrecision                 0.9654          0.9466          1.0000         \nRecall                    0.9760          0.9040          1.0000         \nF1-Score                  0.9707          0.9248          1.0000         \nROC-AUC                   0.9941          0.9798          1.0000         \nTPR @ 0.01% FPR           0.2580          0.3590          1.0000         \nTPR @ 0.1% FPR            0.5040          0.5610          1.0000         \nTPR @ 1% FPR              0.8700          0.7640          1.0000         \n\n======================================================================\nBASELINE COMPARISON\n======================================================================\n\nBased on research papers:\n  RoBERTa (Email):     Accuracy: 98.45%, F1: 0.98\n  URLTran (URL):       Accuracy: 99.67%, TPR@0.01%FPR: 86.80%\n  URLNet (Baseline):   Accuracy: 99.45%, TPR@0.01%FPR: 71.20%\n  Texception:          Accuracy: 99.66%, TPR@0.01%FPR: 52.15%\n\n======================================================================\n‚úÖ TRAINING COMPLETED SUCCESSFULLY!\n======================================================================\n\nüì¶ Saved artifacts:\n  1. ./email_phishing_model/\n  2. ./url_phishing_model/\n  3. ./umpire_model/\n  4. comprehensive_training_summary.json\n  5. ROC curves and confusion matrices (PNG files)\n\nüß™ Ready for testing! Use the testing code to evaluate.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\"\nTesting Code for Multi-Agent Phishing Detection System\nComprehensive evaluation with metrics from research papers\n\"\"\"\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nimport json\nfrom sklearn.metrics import (\n    accuracy_score, \n    classification_report, \n    confusion_matrix,\n    precision_recall_fscore_support,\n    roc_curve,\n    auc,\n    roc_auc_score\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# STEP 1: Load All Three Models\n# ============================================================================\n\nprint(\"=\" * 70)\nprint(\"LOADING TRAINED MODELS\")\nprint(\"=\" * 70)\n\ntry:\n    # Load Umpire Model\n    print(\"\\nüì• Loading Umpire Model...\")\n    umpire_tokenizer = DistilBertTokenizer.from_pretrained('./umpire_model')\n    umpire_model = DistilBertForSequenceClassification.from_pretrained('./umpire_model')\n    umpire_model.eval()\n    print(\"‚úì Umpire model loaded\")\n\n    # Load Email Phishing Model\n    print(\"\\nüì• Loading Email Phishing Model...\")\n    email_tokenizer = DistilBertTokenizer.from_pretrained('./email_phishing_model')\n    email_model = DistilBertForSequenceClassification.from_pretrained('./email_phishing_model')\n    email_model.eval()\n    print(\"‚úì Email phishing model loaded\")\n\n    # Load URL Phishing Model\n    print(\"\\nüì• Loading URL Phishing Model...\")\n    url_tokenizer = DistilBertTokenizer.from_pretrained('./url_phishing_model')\n    url_model = DistilBertForSequenceClassification.from_pretrained('./url_phishing_model')\n    url_model.eval()\n    print(\"‚úì URL phishing model loaded\")\nexcept Exception as e:\n    print(f\"\\n‚ùå Error loading models: {e}\")\n    print(\"\\nPlease ensure you've run the training code first!\")\n    exit(1)\n\n# ============================================================================\n# STEP 2: Define Comprehensive Metrics Functions\n# ============================================================================\n\ndef calculate_tpr_at_fpr(y_true, y_scores, fpr_threshold=0.01):\n    \"\"\"Calculate TPR at specific FPR threshold (URLTran paper metric)\"\"\"\n    try:\n        fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n        idx = np.where(fpr <= fpr_threshold)[0]\n        if len(idx) > 0:\n            return tpr[idx[-1]]\n    except:\n        pass\n    return 0.0\n\ndef calculate_comprehensive_metrics(y_true, y_pred, y_scores):\n    \"\"\"Calculate all metrics from both research papers\"\"\"\n    \n    # Basic metrics (RoBERTa paper)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        y_true, y_pred, average='binary', zero_division=0\n    )\n    accuracy = accuracy_score(y_true, y_pred)\n    \n    # Per-class metrics\n    precision_per_class, recall_per_class, f1_per_class, support = \\\n        precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n    \n    # ROC-AUC metrics (URLTran paper)\n    try:\n        roc_auc = roc_auc_score(y_true, y_scores)\n    except:\n        roc_auc = 0.0\n    \n    # TPR at various FPR thresholds (URLTran paper)\n    tpr_0001 = calculate_tpr_at_fpr(y_true, y_scores, 0.0001)  # 0.01% FPR\n    tpr_001 = calculate_tpr_at_fpr(y_true, y_scores, 0.001)    # 0.1% FPR\n    tpr_01 = calculate_tpr_at_fpr(y_true, y_scores, 0.01)      # 1% FPR\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'roc_auc': roc_auc,\n        'tpr@0.01%_fpr': tpr_0001,\n        'tpr@0.1%_fpr': tpr_001,\n        'tpr@1%_fpr': tpr_01,\n        'confusion_matrix': {\n            'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n        },\n        'per_class': {\n            'legitimate': {\n                'precision': precision_per_class[0],\n                'recall': recall_per_class[0],\n                'f1': f1_per_class[0],\n                'support': int(support[0])\n            },\n            'phishing': {\n                'precision': precision_per_class[1],\n                'recall': recall_per_class[1],\n                'f1': f1_per_class[1],\n                'support': int(support[1])\n            }\n        }\n    }\n\n# ============================================================================\n# STEP 3: Define Prediction Functions\n# ============================================================================\n\ndef predict_single(text, tokenizer, model, device='cpu'):\n    \"\"\"Make prediction for a single text input with confidence scores\"\"\"\n    model.to(device)\n    model.eval()\n    \n    inputs = tokenizer(\n        text,\n        truncation=True,\n        padding=True,\n        max_length=128,\n        return_tensors='pt'\n    ).to(device)\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        probabilities = torch.softmax(logits, dim=-1)\n        prediction = torch.argmax(probabilities, dim=-1).item()\n        confidence = probabilities[0][prediction].item()\n    \n    return prediction, confidence, probabilities[0].cpu().numpy()\n\ndef predict_batch(texts, tokenizer, model, device='cpu', batch_size=32):\n    \"\"\"Batch prediction for efficiency\"\"\"\n    model.to(device)\n    model.eval()\n    \n    all_predictions = []\n    all_scores = []\n    \n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        \n        inputs = tokenizer(\n            batch_texts,\n            truncation=True,\n            padding=True,\n            max_length=128,\n            return_tensors='pt'\n        ).to(device)\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            logits = outputs.logits\n            probabilities = torch.softmax(logits, dim=-1)\n            predictions = torch.argmax(probabilities, dim=-1)\n            \n            all_predictions.extend(predictions.cpu().numpy())\n            all_scores.extend(probabilities[:, 1].cpu().numpy())\n    \n    return np.array(all_predictions), np.array(all_scores)\n\ndef multi_agent_predict(text, verbose=True):\n    \"\"\"\n    Complete multi-agent prediction pipeline with detailed metrics\n    \"\"\"\n    \n    # Step 1: Umpire routing decision\n    umpire_pred, umpire_conf, umpire_probs = predict_single(text, umpire_tokenizer, umpire_model)\n    \n    request_type = \"EMAIL\" if umpire_pred == 0 else \"URL\"\n    \n    if verbose:\n        print(f\"\\n{'=' * 70}\")\n        print(f\"üéØ UMPIRE DECISION: {request_type}\")\n        print(f\"   Confidence: {umpire_conf:.4f}\")\n        print(f\"   Probabilities - Email: {umpire_probs[0]:.4f}, URL: {umpire_probs[1]:.4f}\")\n    \n    # Step 2: Route to specialist model\n    if umpire_pred == 0:  # Email\n        specialist_pred, specialist_conf, specialist_probs = predict_single(\n            text, email_tokenizer, email_model\n        )\n        specialist_name = \"Email Phishing Model\"\n    else:  # URL\n        specialist_pred, specialist_conf, specialist_probs = predict_single(\n            text, url_tokenizer, url_model\n        )\n        specialist_name = \"URL Phishing Model\"\n    \n    # Step 3: Final decision\n    final_verdict = \"PHISHING\" if specialist_pred == 1 else \"LEGITIMATE\"\n    \n    if verbose:\n        print(f\"\\nüîç {specialist_name.upper()}\")\n        print(f\"   Verdict: {final_verdict}\")\n        print(f\"   Confidence: {specialist_conf:.4f}\")\n        print(f\"   Probabilities - Legitimate: {specialist_probs[0]:.4f}, Phishing: {specialist_probs[1]:.4f}\")\n        print(f\"{'=' * 70}\\n\")\n    \n    return {\n        'text': text[:100] + '...' if len(text) > 100 else text,\n        'umpire_decision': request_type,\n        'umpire_confidence': umpire_conf,\n        'umpire_prediction': umpire_pred,\n        'specialist_model': specialist_name,\n        'final_verdict': final_verdict,\n        'specialist_confidence': specialist_conf,\n        'specialist_prediction': specialist_pred,\n        'specialist_score': specialist_probs[1]\n    }\n\n# ============================================================================\n# STEP 4: Predefined Examples Test\n# ============================================================================\n\ndef test_examples():\n    \"\"\"Test with predefined examples\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"TESTING WITH PREDEFINED EXAMPLES\")\n    print(\"=\" * 70)\n    \n    examples = [\n        {\n            'text': 'Congratulations! You have won $1,000,000 in the Microsoft Lottery! Click here to claim your prize now before it expires! http://win-prize-now.com/claim',\n            'type': 'email',\n            'expected': 'phishing'\n        },\n        {\n            'text': 'http://paypal-security-update.suspicious-domain.com/verify-account.php?id=12345',\n            'type': 'url',\n            'expected': 'phishing'\n        },\n        {\n            'text': 'Your meeting with the team has been scheduled for tomorrow at 2:00 PM in Conference Room B. Please confirm your attendance by replying to this email.',\n            'type': 'email',\n            'expected': 'legitimate'\n        },\n        {\n            'text': 'https://www.google.com/search?q=machine+learning',\n            'type': 'url',\n            'expected': 'legitimate'\n        },\n        {\n            'text': 'URGENT ACTION REQUIRED: Your account will be suspended in 24 hours unless you verify your identity immediately. Click here: http://secure-bank-verify.ru/login',\n            'type': 'email',\n            'expected': 'phishing'\n        },\n        {\n            'text': 'https://github.com/pytorch/pytorch',\n            'type': 'url',\n            'expected': 'legitimate'\n        },\n        {\n            'text': 'Dear customer, we detected unusual activity on your account. Please update your payment information to avoid service interruption.',\n            'type': 'email',\n            'expected': 'phishing'\n        },\n        {\n            'text': 'http://www.microsoft.com/en-us/security',\n            'type': 'url',\n            'expected': 'legitimate'\n        }\n    ]\n    \n    correct_predictions = 0\n    total_predictions = len(examples)\n    \n    for i, example in enumerate(examples, 1):\n        print(f\"\\n{'‚îÄ' * 70}\")\n        print(f\"Example {i}/{total_predictions}: {example['type'].upper()}\")\n        print(f\"Expected: {example['expected'].upper()}\")\n        print(f\"Text: {example['text'][:80]}...\")\n        \n        result = multi_agent_predict(example['text'], verbose=True)\n        \n        # Check if prediction matches expected\n        predicted_label = result['final_verdict'].lower()\n        if predicted_label == example['expected']:\n            correct_predictions += 1\n            print(\"‚úÖ CORRECT PREDICTION\")\n        else:\n            print(\"‚ùå INCORRECT PREDICTION\")\n    \n    # Summary\n    accuracy = correct_predictions / total_predictions\n    print(f\"\\n{'=' * 70}\")\n    print(f\"PREDEFINED EXAMPLES SUMMARY\")\n    print(f\"{'=' * 70}\")\n    print(f\"Correct Predictions: {correct_predictions}/{total_predictions}\")\n    print(f\"Accuracy: {accuracy:.2%}\")\n\n# ============================================================================\n# STEP 5: Interactive Testing\n# ============================================================================\n\ndef interactive_test():\n    \"\"\"Interactive testing mode\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"INTERACTIVE TESTING MODE\")\n    print(\"=\" * 70)\n    print(\"\\nEnter text to test (or 'quit' to exit)\")\n    print(\"You can test emails or URLs\\n\")\n    \n    while True:\n        try:\n            text = input(\"üìù Enter text: \").strip()\n            \n            if text.lower() == 'quit':\n                print(\"\\nüëã Exiting interactive mode...\")\n                break\n            \n            if not text:\n                print(\"‚ö†Ô∏è  Please enter some text!\\n\")\n                continue\n            \n            result = multi_agent_predict(text, verbose=True)\n            \n        except KeyboardInterrupt:\n            print(\"\\n\\nüëã Exiting interactive mode...\")\n            break\n        except Exception as e:\n            print(f\"\\n‚ö†Ô∏è  Error: {e}\\n\")\n\n# ============================================================================\n# STEP 6: Generate Comparison Table with Baselines\n# ============================================================================\n\ndef generate_comparison_table():\n    \"\"\"Generate comparison table with baseline models from papers\"\"\"\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"COMPARISON WITH BASELINE MODELS FROM RESEARCH PAPERS\")\n    print(\"=\" * 70)\n    \n    # Load our results\n    try:\n        with open('comprehensive_training_summary.json', 'r') as f:\n            summary = json.load(f)\n        \n        email_metrics = summary['email_model']['metrics']\n        url_metrics = summary['url_model']['metrics']\n        umpire_metrics = summary['umpire_model']['metrics']\n    except:\n        print(\"\\n‚ö†Ô∏è  Could not load training summary. Run training first!\")\n        return\n    \n    # Define baseline data from papers\n    print(\"\\nüìä Performance Comparison:\")\n    print(\"\\n\" + \"-\" * 70)\n    print(\"EMAIL PHISHING DETECTION\")\n    print(\"-\" * 70)\n    print(f\"{'Model':<25} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n    print(\"-\" * 70)\n    print(f\"{'RoBERTa (Paper)':<25} {0.9845:<12.4f} {0.97:<12.4f} {1.00:<12.4f} {0.98:<12.4f}\")\n    print(f\"{'Our Email Model':<25} {email_metrics['accuracy']:<12.4f} {email_metrics['precision']:<12.4f} {email_metrics['recall']:<12.4f} {email_metrics['f1_score']:<12.4f}\")\n    \n    print(\"\\n\" + \"-\" * 70)\n    print(\"URL PHISHING DETECTION\")\n    print(\"-\" * 70)\n    print(f\"{'Model':<25} {'Accuracy':<12} {'F1-Score':<12} {'TPR@0.01%FPR':<15}\")\n    print(\"-\" * 70)\n    print(f\"{'URLTran_BERT (Paper)':<25} {0.9967:<12.4f} {0.9971:<12.4f} {0.8680:<15.4f}\")\n    print(f\"{'URLNet (Paper)':<25} {0.9945:<12.4f} {0.9954:<12.4f} {0.7120:<15.4f}\")\n    print(f\"{'Texception (Paper)':<25} {0.9966:<12.4f} {0.9969:<12.4f} {0.5215:<15.4f}\")\n    print(f\"{'Our URL Model':<25} {url_metrics['accuracy']:<12.4f} {url_metrics['f1_score']:<12.4f} {url_metrics['tpr@0.01%_fpr']:<15.4f}\")\n    \n    print(\"\\n\" + \"-\" * 70)\n    print(\"UMPIRE (ROUTING) MODEL\")\n    print(\"-\" * 70)\n    print(f\"Accuracy: {umpire_metrics['accuracy']:.4f}\")\n    print(f\"F1-Score: {umpire_metrics['f1_score']:.4f}\")\n    \n    # Performance summary\n    print(\"\\n\" + \"=\" * 70)\n    print(\"PERFORMANCE ANALYSIS\")\n    print(\"=\" * 70)\n    \n    print(f\"\\n‚úÖ Email Model:\")\n    print(f\"   Accuracy: {email_metrics['accuracy']:.4f}\")\n    print(f\"   Status: {'Excellent' if email_metrics['accuracy'] > 0.95 else 'Good' if email_metrics['accuracy'] > 0.90 else 'Needs Improvement'}\")\n    \n    print(f\"\\n‚úÖ URL Model:\")\n    print(f\"   Accuracy: {url_metrics['accuracy']:.4f}\")\n    print(f\"   TPR@0.01%FPR: {url_metrics['tpr@0.01%_fpr']:.4f}\")\n    print(f\"   Status: {'Excellent' if url_metrics['accuracy'] > 0.95 else 'Good' if url_metrics['accuracy'] > 0.90 else 'Needs Improvement'}\")\n    \n    print(f\"\\n‚úÖ Umpire Model:\")\n    print(f\"   Routing Accuracy: {umpire_metrics['accuracy']:.4f}\")\n    print(f\"   Status: {'Excellent' if umpire_metrics['accuracy'] > 0.95 else 'Good' if umpire_metrics['accuracy'] > 0.90 else 'Needs Improvement'}\")\n\n# ============================================================================\n# STEP 7: Main Testing Menu\n# ============================================================================\n\ndef main_menu():\n    \"\"\"Main testing menu with all options\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"MULTI-AGENT PHISHING DETECTION SYSTEM - COMPREHENSIVE TESTING\")\n    print(\"=\" * 70)\n    \n    while True:\n        print(\"\\nüìã Select testing mode:\")\n        print(\"  1. Test with predefined examples\")\n        print(\"  2. Interactive testing (manual input)\")\n        print(\"  3. View performance comparison with baselines\")\n        print(\"  4. Run all tests\")\n        print(\"  5. Exit\")\n        \n        try:\n            choice = input(\"\\nüëâ Enter your choice (1-5): \").strip()\n            \n            if choice == '1':\n                test_examples()\n            \n            elif choice == '2':\n                interactive_test()\n            \n            elif choice == '3':\n                generate_comparison_table()\n            \n            elif choice == '4':\n                print(\"\\nüîÑ Running all tests...\\n\")\n                test_examples()\n                generate_comparison_table()\n                print(\"\\n‚úÖ All tests completed!\")\n            \n            elif choice == '5':\n                print(\"\\nüëã Goodbye!\")\n                break\n            \n            else:\n                print(\"‚ö†Ô∏è  Invalid choice! Please enter 1-5.\")\n        \n        except KeyboardInterrupt:\n            print(\"\\n\\nüëã Goodbye!\")\n            break\n        except Exception as e:\n            print(f\"\\n‚ö†Ô∏è  Error: {e}\")\n\n# ============================================================================\n# RUN TESTING\n# ============================================================================\n\nif __name__ == \"__main__\":\n    print(\"\\nüöÄ Starting Multi-Agent Phishing Detection System Testing\")\n    print(\"=\" * 70)\n    \n    # Run predefined examples first\n    test_examples()\n    \n    # Show comparison with baselines\n    generate_comparison_table()\n    \n    # Start interactive menu\n    print(\"\\n\\nüéØ Ready for additional testing!\")\n    main_menu()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T19:49:04.785768Z","iopub.execute_input":"2025-11-09T19:49:04.786080Z","iopub.status.idle":"2025-11-09T19:49:47.996175Z","shell.execute_reply.started":"2025-11-09T19:49:04.786055Z","shell.execute_reply":"2025-11-09T19:49:47.995378Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nLOADING TRAINED MODELS\n======================================================================\n\nüì• Loading Umpire Model...\n‚úì Umpire model loaded\n\nüì• Loading Email Phishing Model...\n‚úì Email phishing model loaded\n\nüì• Loading URL Phishing Model...\n‚úì URL phishing model loaded\n\nüöÄ Starting Multi-Agent Phishing Detection System Testing\n======================================================================\n\n======================================================================\nTESTING WITH PREDEFINED EXAMPLES\n======================================================================\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 1/8: EMAIL\nExpected: PHISHING\nText: Congratulations! You have won $1,000,000 in the Microsoft Lottery! Click here to...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.8192\n   Probabilities - Legitimate: 0.8192, Phishing: 0.1808\n======================================================================\n\n‚ùå INCORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 2/8: URL\nExpected: PHISHING\nText: http://paypal-security-update.suspicious-domain.com/verify-account.php?id=12345...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: PHISHING\n   Confidence: 0.9824\n   Probabilities - Legitimate: 0.0176, Phishing: 0.9824\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 3/8: EMAIL\nExpected: LEGITIMATE\nText: Your meeting with the team has been scheduled for tomorrow at 2:00 PM in Confere...\n\n======================================================================\nüéØ UMPIRE DECISION: EMAIL\n   Confidence: 0.9582\n   Probabilities - Email: 0.9582, URL: 0.0418\n\nüîç EMAIL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9234\n   Probabilities - Legitimate: 0.9234, Phishing: 0.0766\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 4/8: URL\nExpected: LEGITIMATE\nText: https://www.google.com/search?q=machine+learning...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9942\n   Probabilities - Legitimate: 0.9942, Phishing: 0.0058\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 5/8: EMAIL\nExpected: PHISHING\nText: URGENT ACTION REQUIRED: Your account will be suspended in 24 hours unless you ve...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: PHISHING\n   Confidence: 0.9573\n   Probabilities - Legitimate: 0.0427, Phishing: 0.9573\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 6/8: URL\nExpected: LEGITIMATE\nText: https://github.com/pytorch/pytorch...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9849\n   Probabilities - Legitimate: 0.9849, Phishing: 0.0151\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 7/8: EMAIL\nExpected: PHISHING\nText: Dear customer, we detected unusual activity on your account. Please update your ...\n\n======================================================================\nüéØ UMPIRE DECISION: EMAIL\n   Confidence: 0.9998\n   Probabilities - Email: 0.9998, URL: 0.0002\n\nüîç EMAIL PHISHING MODEL\n   Verdict: PHISHING\n   Confidence: 0.7904\n   Probabilities - Legitimate: 0.2096, Phishing: 0.7904\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 8/8: URL\nExpected: LEGITIMATE\nText: http://www.microsoft.com/en-us/security...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9919\n   Probabilities - Legitimate: 0.9919, Phishing: 0.0081\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n======================================================================\nPREDEFINED EXAMPLES SUMMARY\n======================================================================\nCorrect Predictions: 7/8\nAccuracy: 87.50%\n\n======================================================================\nCOMPARISON WITH BASELINE MODELS FROM RESEARCH PAPERS\n======================================================================\n\nüìä Performance Comparison:\n\n----------------------------------------------------------------------\nEMAIL PHISHING DETECTION\n----------------------------------------------------------------------\nModel                     Accuracy     Precision    Recall       F1-Score    \n----------------------------------------------------------------------\nRoBERTa (Paper)           0.9845       0.9700       1.0000       0.9800      \nOur Email Model           0.9705       0.9654       0.9760       0.9707      \n\n----------------------------------------------------------------------\nURL PHISHING DETECTION\n----------------------------------------------------------------------\nModel                     Accuracy     F1-Score     TPR@0.01%FPR   \n----------------------------------------------------------------------\nURLTran_BERT (Paper)      0.9967       0.9971       0.8680         \nURLNet (Paper)            0.9945       0.9954       0.7120         \nTexception (Paper)        0.9966       0.9969       0.5215         \nOur URL Model             0.9265       0.9248       0.3590         \n\n----------------------------------------------------------------------\nUMPIRE (ROUTING) MODEL\n----------------------------------------------------------------------\nAccuracy: 1.0000\nF1-Score: 1.0000\n\n======================================================================\nPERFORMANCE ANALYSIS\n======================================================================\n\n‚úÖ Email Model:\n   Accuracy: 0.9705\n   Status: Excellent\n\n‚úÖ URL Model:\n   Accuracy: 0.9265\n   TPR@0.01%FPR: 0.3590\n   Status: Good\n\n‚úÖ Umpire Model:\n   Routing Accuracy: 1.0000\n   Status: Excellent\n\n\nüéØ Ready for additional testing!\n\n======================================================================\nMULTI-AGENT PHISHING DETECTION SYSTEM - COMPREHENSIVE TESTING\n======================================================================\n\nüìã Select testing mode:\n  1. Test with predefined examples\n  2. Interactive testing (manual input)\n  3. View performance comparison with baselines\n  4. Run all tests\n  5. Exit\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nüëâ Enter your choice (1-5):  1\n"},{"name":"stdout","text":"\n======================================================================\nTESTING WITH PREDEFINED EXAMPLES\n======================================================================\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 1/8: EMAIL\nExpected: PHISHING\nText: Congratulations! You have won $1,000,000 in the Microsoft Lottery! Click here to...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.8192\n   Probabilities - Legitimate: 0.8192, Phishing: 0.1808\n======================================================================\n\n‚ùå INCORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 2/8: URL\nExpected: PHISHING\nText: http://paypal-security-update.suspicious-domain.com/verify-account.php?id=12345...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: PHISHING\n   Confidence: 0.9824\n   Probabilities - Legitimate: 0.0176, Phishing: 0.9824\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 3/8: EMAIL\nExpected: LEGITIMATE\nText: Your meeting with the team has been scheduled for tomorrow at 2:00 PM in Confere...\n\n======================================================================\nüéØ UMPIRE DECISION: EMAIL\n   Confidence: 0.9582\n   Probabilities - Email: 0.9582, URL: 0.0418\n\nüîç EMAIL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9234\n   Probabilities - Legitimate: 0.9234, Phishing: 0.0766\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 4/8: URL\nExpected: LEGITIMATE\nText: https://www.google.com/search?q=machine+learning...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9942\n   Probabilities - Legitimate: 0.9942, Phishing: 0.0058\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 5/8: EMAIL\nExpected: PHISHING\nText: URGENT ACTION REQUIRED: Your account will be suspended in 24 hours unless you ve...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: PHISHING\n   Confidence: 0.9573\n   Probabilities - Legitimate: 0.0427, Phishing: 0.9573\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 6/8: URL\nExpected: LEGITIMATE\nText: https://github.com/pytorch/pytorch...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9849\n   Probabilities - Legitimate: 0.9849, Phishing: 0.0151\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 7/8: EMAIL\nExpected: PHISHING\nText: Dear customer, we detected unusual activity on your account. Please update your ...\n\n======================================================================\nüéØ UMPIRE DECISION: EMAIL\n   Confidence: 0.9998\n   Probabilities - Email: 0.9998, URL: 0.0002\n\nüîç EMAIL PHISHING MODEL\n   Verdict: PHISHING\n   Confidence: 0.7904\n   Probabilities - Legitimate: 0.2096, Phishing: 0.7904\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nExample 8/8: URL\nExpected: LEGITIMATE\nText: http://www.microsoft.com/en-us/security...\n\n======================================================================\nüéØ UMPIRE DECISION: URL\n   Confidence: 1.0000\n   Probabilities - Email: 0.0000, URL: 1.0000\n\nüîç URL PHISHING MODEL\n   Verdict: LEGITIMATE\n   Confidence: 0.9919\n   Probabilities - Legitimate: 0.9919, Phishing: 0.0081\n======================================================================\n\n‚úÖ CORRECT PREDICTION\n\n======================================================================\nPREDEFINED EXAMPLES SUMMARY\n======================================================================\nCorrect Predictions: 7/8\nAccuracy: 87.50%\n\nüìã Select testing mode:\n  1. Test with predefined examples\n  2. Interactive testing (manual input)\n  3. View performance comparison with baselines\n  4. Run all tests\n  5. Exit\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nüëâ Enter your choice (1-5):  3\n"},{"name":"stdout","text":"\n======================================================================\nCOMPARISON WITH BASELINE MODELS FROM RESEARCH PAPERS\n======================================================================\n\nüìä Performance Comparison:\n\n----------------------------------------------------------------------\nEMAIL PHISHING DETECTION\n----------------------------------------------------------------------\nModel                     Accuracy     Precision    Recall       F1-Score    \n----------------------------------------------------------------------\nRoBERTa (Paper)           0.9845       0.9700       1.0000       0.9800      \nOur Email Model           0.9705       0.9654       0.9760       0.9707      \n\n----------------------------------------------------------------------\nURL PHISHING DETECTION\n----------------------------------------------------------------------\nModel                     Accuracy     F1-Score     TPR@0.01%FPR   \n----------------------------------------------------------------------\nURLTran_BERT (Paper)      0.9967       0.9971       0.8680         \nURLNet (Paper)            0.9945       0.9954       0.7120         \nTexception (Paper)        0.9966       0.9969       0.5215         \nOur URL Model             0.9265       0.9248       0.3590         \n\n----------------------------------------------------------------------\nUMPIRE (ROUTING) MODEL\n----------------------------------------------------------------------\nAccuracy: 1.0000\nF1-Score: 1.0000\n\n======================================================================\nPERFORMANCE ANALYSIS\n======================================================================\n\n‚úÖ Email Model:\n   Accuracy: 0.9705\n   Status: Excellent\n\n‚úÖ URL Model:\n   Accuracy: 0.9265\n   TPR@0.01%FPR: 0.3590\n   Status: Good\n\n‚úÖ Umpire Model:\n   Routing Accuracy: 1.0000\n   Status: Excellent\n\nüìã Select testing mode:\n  1. Test with predefined examples\n  2. Interactive testing (manual input)\n  3. View performance comparison with baselines\n  4. Run all tests\n  5. Exit\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nüëâ Enter your choice (1-5):  5\n"},{"name":"stdout","text":"\nüëã Goodbye!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}